{"cells":[{"cell_type":"markdown","metadata":{"id":"am6zt8HjafSG"},"source":["# **Installing the dependencies**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZ0r9XqNgOsj"},"outputs":[],"source":["#https://github.com/graykode/nlp-tutorial/blob/master/5-1.Transformer/Transformer.py#L45"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3sQpEqk_gN6R"},"outputs":[],"source":["!pip install transformers torch\n","!pip install -U SentencePiece\n","!pip install accelerate -U\n","!pip install datasets"]},{"cell_type":"markdown","metadata":{"id":"ezRF9z5FazqL"},"source":["# **Connecting google colab to drive**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZtjbFMNVE2uH"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"gQ0j-j6Pa7Mn"},"source":["# **Importing the dependencies**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OC0GkspcgaSv"},"outputs":[],"source":["import json\n","import random\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from transformers import RobertaTokenizer, RobertaForSequenceClassification, T5Tokenizer, T5ForSequenceClassification,TrainingArguments, Trainer\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import re\n","import random\n","from datasets import Dataset\n","import numpy as np\n","import math\n","import pandas as pd\n","from collections import Counter\n","import sys\n","import json\n","# visualization libraries\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# pytorch libraries\n","import torch # the main pytorch library\n","import torch.nn as nn # the sub-library containing Softmax, Module and other useful functions\n","import torch.optim as optim # the sub-library containing the common optimizers (SGD, Adam, etc.)\n","\n","# huggingface's transformers library\n","#from transformers import RobertaForTokenClassification, RobertaTokenizer\n","from transformers import RobertaForTokenClassification, RobertaTokenizer\n","from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n","\n","# huggingface's datasets library\n","from datasets import load_dataset\n","\n","# the tqdm library used to show the iteration progress\n","import tqdm\n","tqdmn = tqdm.notebook.tqdm#tqdm.tqdm# tqdm.notebook.tqdm\n","\n","from datasets import load_dataset\n","import os\n","from transformers import get_scheduler\n","from datasets import Dataset\n","from sklearn.metrics import classification_report\n","import matplotlib.pyplot as plt\n","import copy\n"]},{"cell_type":"markdown","metadata":{"id":"fBy8UZhcnAza"},"source":["## Data format\n","\n","2 json files - `surprise.data` contains utterances, `surprise.solution` contains corresponding intents\n","\n","Format of `surprise.data`\n","\n","```json\n","{\"indoml_id\": \"surprise|11109\", \"id\": \"11109\", \"utt\": \"Can I make a reservation at Buffalo Wild Wings?\"}\n","{\"indoml_id\": \"surprise|11051\", \"id\": \"11051\", \"utt\": \"Can I book a table for tonight at Bella Vita?\"}\n","....\n","```\n","\n","Format of `surprise.solution` (contains 150 labels)\n","\n","```json\n","{\"indoml_id\": \"surprise|11109\", \"intent\": \"accept reservations\"}\n","{\"indoml_id\": \"surprise|11051\", \"intent\": \"accept reservations\"}\n","....\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"MORlKlcxbJIv"},"source":["# **Loading the data and solution of the surprise dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lNGbonX3giFg"},"outputs":[],"source":["# Load the data from the JSON files\n","with open('/home/naive123/nlp/Sumit/massive/suprise/surprise_data/surprise.data', 'r') as data_file:\n","    data = [json.loads(line) for line in data_file] # converting string to object using json.loads\n","\n","with open('/home/naive123/nlp/Sumit/massive/suprise/surprise_data/surprise.solution', 'r') as solution_file:\n","    solutions = [json.loads(line) for line in solution_file] # converting string to object using json.loads\n","\n","# with open('/content/drive/MyDrive/Intent_classification_IIT_BOMBAY/Dataset/massive_test_phase2_data/massive_test.data', 'r') as test_file:\n","#     test = [json.loads(line) for line in test_file]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2g5qBkgLwBH","outputId":"47136853-17ef-4faa-abd1-da4e9c82397c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Oct 11 13:07:23 2023       \r\n","+-----------------------------------------------------------------------------+\r\n","| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |\r\n","|-------------------------------+----------------------+----------------------+\r\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n","|                               |                      |               MIG M. |\r\n","|===============================+======================+======================|\r\n","|   0  Quadro RTX 6000     Off  | 00000000:81:00.0 Off |                  Off |\r\n","| 34%   31C    P8     6W / 260W |    161MiB / 24217MiB |      0%      Default |\r\n","|                               |                      |                  N/A |\r\n","+-------------------------------+----------------------+----------------------+\r\n","                                                                               \r\n","+-----------------------------------------------------------------------------+\r\n","| Processes:                                                                  |\r\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n","|        ID   ID                                                   Usage      |\r\n","|=============================================================================|\r\n","|    0   N/A  N/A      1370      G   /usr/lib/xorg/Xorg                 15MiB |\r\n","|    0   N/A  N/A      2236      G   ...mviewer/tv_bin/TeamViewer       27MiB |\r\n","|    0   N/A  N/A      4505      G   /usr/lib/xorg/Xorg                 64MiB |\r\n","|    0   N/A  N/A      4618      G   /usr/bin/gnome-shell               29MiB |\r\n","+-----------------------------------------------------------------------------+\r\n"]}],"source":["!nvidia-smi\n"]},{"cell_type":"markdown","metadata":{"id":"eG_y4F3kbatu"},"source":["# **loading and perform preprocessing on blind dataset(Testing dataset)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KoHGwhfNH8Kr"},"outputs":[],"source":["solution_path='/home/naive123/nlp/Sumit/massive/suprise/massive_test.data'\n","with open(solution_path,'r') as file:\n","\tfiles=file.readlines()\n","\n","test_list=[]\n","for line in files:\n","\tline=line.strip('\\n')\n","\tline=json.loads(line)\n","\ttest_list.append(line)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jlHaeBjqFr1","outputId":"7103fb63-8747-4715-8b98-98bf163c94c6"},"outputs":[{"data":{"text/plain":["[{'indoml_id': 1,\n","  'utt': 'Kindly show me my entire transaction record from the beginning of this year.'},\n"," {'indoml_id': 2, 'utt': 'Could you help me get this thing delivered today?'},\n"," {'indoml_id': 3, 'utt': 'Can you join forces with my mobile?'},\n"," {'indoml_id': 4,\n","  'utt': 'Can I get an update on the interest rate for my TD Bank savings account?'},\n"," {'indoml_id': 5, 'utt': \"Absolutely! I'd love some more coffee too.\"},\n"," {'indoml_id': 6,\n","  'utt': 'What are the necessary tools required to jump-start my vehicle?'},\n"," {'indoml_id': 7,\n","  'utt': 'how long does it take for my credit score to recover from a bankruptcy filing?'},\n"," {'indoml_id': 8, 'utt': 'Could you please play the next track?'},\n"," {'indoml_id': 9,\n","  'utt': 'How do I go about increasing my credit limit on my Discover it cashback card?'},\n"," {'indoml_id': 10,\n","  'utt': 'Kindly provide me with the exact date of expiration of my Capital One card.'},\n"," {'indoml_id': 11,\n","  'utt': 'may I ask if you would prefer to communicate in swahili?'},\n"," {'indoml_id': 12,\n","  'utt': 'What are the deadlines for filing my state and federal taxes this year?'},\n"," {'indoml_id': 13,\n","  'utt': \"Today's fun fact: The Great Barrier Reef is so big that it can be seen from space! It spans over 2,300 kilometers (1,400 miles).\"},\n"," {'indoml_id': 14,\n","  'utt': 'How can I ensure that my paycheck is deposited directly into my account every month?'},\n"," {'indoml_id': 15,\n","  'utt': 'I would like you to move the dentist appointment to my to-do list for tomorrow.'},\n"," {'indoml_id': 16,\n","  'utt': 'I think one of my tires is low on air; can you check it for me?'},\n"," {'indoml_id': 17,\n","  'utt': 'Fun fact: The longest word in English without any repeated letters is \"pneumonoultramicroscopicsilicovolcanoconiosis,\" which refers to a lung disease caused by inhaling very fine silica particles.'},\n"," {'indoml_id': 18,\n","  'utt': 'I am looking to switch to a new provider because I am not satisfied with the service I have been receiving.'},\n"," {'indoml_id': 19,\n","  'utt': 'I seem to have mislaid my mobile device somewhere around here.'},\n"," {'indoml_id': 20, 'utt': 'how do you do?)'}]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["test_list[:20]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-JPWetxglua","outputId":"9555ec1e-01c2-4287-e99e-cc339934f6d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'indoml_id': 'surprise|11109', 'id': '11109', 'utt': 'Can I make a reservation at Buffalo Wild Wings?'}\n"]}],"source":["print(data[0]) # data of the surpirse dataset having id and the utterances"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fXeGT9lLgmgR","outputId":"20e67358-a6d8-4873-8ba6-7cde4bf142d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'indoml_id': 'surprise|11109', 'intent': 'accept reservations'}\n"]}],"source":["\n","print(solutions[0]) # Solutions of the surpise dataset having id and intent for the previous teerances"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3aPEyBAcgpLD","outputId":"063cb75d-303e-4c2c-f37a-47165f3045e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of classes\n","150\n"]}],"source":["# Create a dictionary to map indoml_id to intents\n","intent_map = {item['indoml_id']: item['intent'] for item in solutions}\n","\n","# Split data into train and test sets (2:1) stratified by intent\n","indoml_ids = [item['indoml_id'] for item in data]\n","intents = [intent_map[indoml_id] for indoml_id in indoml_ids]\n","\"\"\"utterances(features) for the dataset\"\"\"\n","utt = [item['utt'] for item in data]\n","\n","num_classes = len(set(intents)) # total number of unique intents are the total number of classes\n","print(\"Number of classes\")\n","print(num_classes)\n","\n","\"\"\"Splitting the dataset into train and test set\"\"\"\n","train_data, test_data, train_labels, test_labels = train_test_split(\n","    utt, intents, test_size=0.10, random_state=42, stratify=intents\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pZS7LGE2eCyq","outputId":"b3e268f9-acf2-49e0-c811-daf4de64ef7c"},"outputs":[{"data":{"text/plain":["(['interest rate',\n","  'restaurant suggestion',\n","  'change language',\n","  'shopping list',\n","  'oil change how'],\n"," 2023)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train_labels[0:5], len(train_labels) # these are basically our intents corrosponding to the utterances for trainin g data(5%) of the data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BQDhtz_XDxKj","outputId":"b66a86f5-65a8-4f80-98e2-4ff20e9f5974"},"outputs":[{"data":{"text/plain":["['interest rate',\n"," 'restaurant suggestion',\n"," 'change language',\n"," 'shopping list',\n"," 'oil change how']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train_labels[0:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GEPViu5yD1Z1","outputId":"ccfd4d21-05a9-41c7-a6fd-0d6ebb588326"},"outputs":[{"data":{"text/plain":["['please tell me what i can expect my us bank interest rate to be.',\n"," 'Can you recommend a great Italian restaurant nearby?',\n"," 'Can you communicate with me in Japanese?',\n"," 'Is there a way to organize my shopping list by categories?',\n"," 'Can you walk me through the process of changing my oil?']"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train_data[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y6zHJm-4tbiO","outputId":"98e60d02-0cec-43d4-d0a7-6ba627236e15"},"outputs":[{"data":{"text/plain":["(['change language', 'yes', 'how old are you', 'who made you', 'smart home'],\n"," 225)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["test_labels[0:5], len(test_labels) # these are basically our intents corrosponding to the utterances for testing data(5%) of the data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3cnOG0OCrs2W","outputId":"c646f046-7f94-4eae-f555-a71abf72ff59"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'restaurant reviews', 'definition', 'next holiday', 'whisper mode', 'damaged card', 'cook time', 'are you a bot', 'what is your name', 'w2', 'do you have pets', 'nutrition info', 'pay bill', 'travel notification', 'redeem rewards', 'flip coin', 'meeting schedule', 'restaurant suggestion', 'tire pressure', 'timer', 'alarm', 'change user name', 'maybe', 'pto used', 'date', 'fun fact', 'what can i ask you', 'order', 'insurance', 'carry on', 'todo list', 'uber', 'recipe', 'find phone', 'improve credit score', 'change ai name', 'freeze account', 'book hotel', 'change volume', 'restaurant reservation', 'timezone', 'next song', 'todo list update', 'calendar', 'taxes', 'travel suggestion', 'rewards balance', 'gas', 'cancel reservation', 'income', 'report fraud', 'international fees', 'reset settings', 'min payment', 'confirm reservation', 'travel alert', 'food last', 'transactions', 'what are your hobbies', 'rollover 401k', 'change speed', 'cancel', 'schedule maintenance', 'plug type', 'credit score', 'reminder', 'spending history', 'calendar update', 'shopping list update', 'transfer', 'tell joke', 'vaccines', 'lost luggage', 'last maintenance', 'share location', 'yes', 'routing', 'text', 'traffic', 'user name', 'interest rate', 'gas type', 'schedule meeting', 'flight status', 'pto balance', 'tire change', 'expiration date', 'pto request status', 'international visa', 'credit limit change', 'calculator', 'distance', 'new card', 'report lost card', 'jump start', 'spelling', 'weather', 'bill due', 'card declined', 'ingredients list', 'ingredient substitution', 'sync device', 'thank you', 'update playlist', 'how busy', 'reminder update', 'replacement card duration', 'who made you', 'bill balance', 'pin change', 'balance', 'account blocked', 'who do you work for', 'meal suggestion', 'exchange rate', 'book flight', 'order status', 'what song', 'order checks', 'mpg', 'how old are you', 'calories', 'measurement conversion', 'pto request', 'insurance change', 'change language', 'current location', 'greeting', 'where are you from', 'application status', 'smart home', 'time', 'car rental', 'apr', 'goodbye', 'accept reservations', 'play music', 'roll dice', 'no', 'change accent', 'meaning of life', 'make call', 'payday', 'oil change when', 'oil change how', 'direct deposit', 'directions', 'translate', 'shopping list', 'credit limit', 'repeat'}\n"]},{"data":{"text/plain":["150"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["intents\n","intents_set=set(intents) # basically represent the total no. of disntics intents(labels) in our surprise dataset(150)\n","print(intents_set)\n","len(intents_set)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4DPRhLPDsNNu"},"outputs":[],"source":["id2label={} # id2label mapping\n","label2id={} # label2id mapping\n","for i, intent in enumerate(intents_set):\n","  id2label[i] = intent\n","  label2id[intent]=i\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"79jTNA-QFshC","outputId":"9265d8a1-f3f9-4e5f-f75e-1fb0c1f43cb3"},"outputs":[{"data":{"text/plain":["[124, 74, 119, 106, 129]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"Convert labels to numeric values from label2id mapping\"\"\"\n","train_int_labels = [label2id[label] for label in train_labels]\n","test_int_labels = [label2id[label] for label in test_labels]\n","test_int_labels[0:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZgEVcySDE2E0","outputId":"c9076844-37b8-47ec-97b1-b7bc507d3e2e"},"outputs":[{"data":{"text/plain":["{'utt': ['Kindly alter my language preference to Japanese.',\n","  \"Absolutely, I couldn't agree more!\",\n","  'how old do you think you will be next year, ai?',\n","  'who is credited with creating your robotics software',\n","  \"What's the wifi password for my living room lamp?\",\n","  'Can you please tell me how much I need to pay for my water bill this month?',\n","  'I would like to add \"Happy\" by Pharrell Williams to my feel-good playlist.',\n","  'I need an alarm to go off at 10 pm to wind down.',\n","  'How do you say \"goodnight\" in Italian?',\n","  \"I'd love to know more about your pets.\",\n","  'Can you tell me if my tires are properly inflated?',\n","  'How good is the APR on my credit card?',\n","  'I am interested in renting an electric car in Seattle for a road trip along the Pacific Coast Highway. Can you provide more information on these types of vehicles?',\n","  'What is the result of subtracting 19 from 37?',\n","  'i want to talk to ben.',\n","  'How do I go about checking my account balance?',\n","  'Have I been spending too much on travel expenses?',\n","  \"I'll be visiting Australia from March 1st to March 10th; could you please inform my bank of my travel plans?\",\n","  'are there any specific vaccinations required for travel to canada?',\n","  'When can I expect to hear back about my day off request?',\n","  'can you provide examples of the types of questions you can answer?',\n","  'May I modify your moniker to something more fitting?',\n","  'How many meetings do I have scheduled for next week?',\n","  'How can I find my current location on a map?',\n","  'What is the average credit score in the United States?',\n","  \"I'm running low on checks for my USAA account; can I get some more?\",\n","  'did you know that the shortest war in history was between Britain and Zanzibar on August 27, 1896?',\n","  'do you have any vinyl records? I want to spin some tunes tonight.',\n","  'How much cash do I currently have in my bank accounts?',\n","  'I would like to request that my account be temporarily locked to prevent any further transactions.',\n","  'What are the recommended vaccinations for travel to France during the summer months',\n","  'Did you know that the shortest war in history was between Britain and Zanzibar on August 27, 1896, and lasted only 38 minutes?',\n","  'How much fuel does my car use for every mile driven?',\n","  'Is there anything important noted on my calendar for today?',\n","  'can i substitute eggplant for zucchini in a vegetarian dish?',\n","  'My damaged card needs to be reported to the company urgently so they can send a replacement.',\n","  \"As I waited at the baggage claim area, I couldn't help but feel anxious about the possibility of never seeing my luggage again.\",\n","  'I need you to order me a new bike, could you please get one from REI?',\n","  'I was hoping to get a new TV, but my card was declined at Costco.',\n","  'What is your preferred moniker?',\n","  \"I've been working hard lately, and I can't wait to see how much I'll be paid this month. It's always a nice surprise.\",\n","  \"Text John and let him know that you're running low on milk.\",\n","  'What is my current balance of PTO days?',\n","  'Can you please transfer $40 from my savings account to my Venmo account',\n","  'I would appreciate it if someone could inform me about the progress of my Chase application.',\n","  \"Well said! Couldn't have put it better myself.\",\n","  'Good day to you! How have you been?',\n","  'Can you please remind me to bring my lunch to work tomorrow?',\n","  'can you please remove watching netflix from my list of tasks?',\n","  \"How long will my account remain inaccessible before it's unblocked?\",\n","  'Kindly update me on the progress of my time-off request.',\n","  'can you help me calculate my self-employment tax?',\n","  \"What's your name, my dear\",\n","  'I need help spelling the word \"mammoth\".',\n","  'Can you explain why the interest rate on my student loans is so high?',\n","  'how long can you keep opened jars of pickles in the fridge',\n","  'Add the exercise routine to my list for today.',\n","  'Kindly guide me through the steps involved in establishing direct deposit for my child support payments.',\n","  'have you discovered your calling in life?',\n","  'Some folks call me Steve.',\n","  'Can you give me an estimate of my annual salary?',\n","  'Can you please share my income statement for the past quarter?',\n","  'What sites are there to see when in Evans?',\n","  'When is the next time off for a holiday around here?',\n","  'how far is it to the next city?',\n","  'Can you provide the definition of \"tintinnabulation\"?',\n","  'What are some beautiful beaches to visit in Bali?',\n","  'Add avocado to my to-do shopping list.',\n","  'Can you tell me my current bank balance so I can make informed financial decisions?',\n","  'I report directly to the CEO.',\n","  'I am looking for information on how to roll over my 401k into a Roth IRA to potentially reduce my tax liability in retirement.',\n","  'How long does it take to see improvements in my credit score after making changes?',\n","  \"let's hear you speak in a different accent!\",\n","  'how many customers does the coffee shop typically serve during rush hour?',\n","  'Can I increase my credit limit on my Bank of America CoreÂ® Secured credit card?',\n","  \"I'm curious to hear how you sound in a Cockney accent.\",\n","  'I need a 30-minute timer for my study session.',\n","  'How does my homeowners insurance policy protect my property from natural disasters?',\n","  'Whats up, buddy? Long time no catch up!',\n","  'Add the fitness class to my calendar every Monday morning.',\n","  'Can you please order me a new set of kitchen utensils from Williams Sonoma?',\n","  'Share a joke that will brighten my day.',\n","  'I need to know when my cable bill is due this month.',\n","  \"I'm calling to confirm my reservation for the concert tonight at 9pm.\",\n","  'What is the minimum payment for my DirecTV bill this month?',\n","  'How many days of vacation time do I have remaining',\n","  'How can I leverage technology to monitor and manage my credit score more effectively?',\n","  'Can you please let me know my rewards balance on my SunTrust bank card?',\n","  'I would appreciate any guidance on how to make a classic beef Wellington dish.',\n","  'call off the meeting scheduled for today.',\n","  'What date did I receive my last payment?',\n","  'Does United Airlines allow passengers to check in their carry-on bags at the gate?',\n","  'Can you provide detailed instructions on how to set up direct deposit',\n","  'Can you tell me if cleaning the garage is on my to-do list for next month',\n","  'The time zone of Italy is what?',\n","  'I would like to know the amount due on my Time Warner Cable bill this month.',\n","  'Do I need a plug adapter for my trip to China?',\n","  \"I'm in dire need of assistance in paying my car insurance premium.\",\n","  'Your rapid-fire delivery is impressive, but I have trouble keeping up; could you please slow down a bit?',\n","  'Can you explain the steps involved in redeeming my credit card points for a brand-new Apple Watch?',\n","  'how do I file for tax extension?',\n","  'Are there any precautions I should take when jump-starting a car to avoid damaging either vehicle or electrical system?',\n","  'Can I expedite the process of receiving a replacement card if I need it urgently?',\n","  'Give my location details to Tom and Alex.',\n","  'I would like to switch to a different health insurance plan that offers better coverage for mental health services.',\n","  'Could you please guide me to the closest movie theater?',\n","  \"It's frustrating when you can't use your own money because of some technical glitch.\",\n","  'where did you come from, the mysterious place that gave birth to your soul',\n","  'Flipping a coin can be a fair and impartial way to make decisions when there are conflicting opinions',\n","  'I want to switch to a different auto insurance provider.',\n","  'bump up the volume.',\n","  'Can you assist me in filing a report for a fraudulent transaction on my PayPal account?',\n","  \"I'm eagerly waiting to find out if my loan application has been accepted.\",\n","  'How many days have I taken off without using my PTO?',\n","  'Set a timer for 20 minutes.',\n","  'It is time to book an oil change appointment.',\n","  'how many square feet are in 1000 square meters?',\n","  'Until we meet again, take care of yourself and keep in touch.',\n","  'How many pets do you have in total?',\n","  \"What's the estimated arrival time of my flight from JFK to LAX?\",\n","  'Can you please update me on the status of my recent purchase?',\n","  'When does my mastercard expire?',\n","  'Shall I help you reset your device to its default settings?',\n","  \"let's see what luck has in store for us.\",\n","  'How long does it take to fly from Tokyo to Sydney',\n","  \"I'd like to request a new PIN for my Capital One credit card.\",\n","  'can you inform me when my fridge last underwent routine checkup?',\n","  'What kind of gas does this car need?',\n","  'How would you rate the ambiance of Bonefish Grill?',\n","  'I need you to roll a 5-sided die for me right away!',\n","  'What were your thoughts on the variety of options at TGI Fridays?',\n","  'find out what this song is?',\n","  'What are the current weather conditions in New York City?',\n","  \"Set an alarm clock for 6 AM so I don't oversleep.\",\n","  'make a reservation for 4 at buffalo wild wings at 8 pm next Tuesday under the name sarah.',\n","  'Is there a warning about traveling to Brazil?',\n","  'Please provide me with the routing number for my capital one account.',\n","  'What are the rates for renting a car in Dallas for a period of two weeks starting from March 1st?',\n","  'how many calories does a slice of pepperoni pizza contain?',\n","  \"let's move on from this track and listen to something else.\",\n","  'can you please inform me of the title of the song currently being played?',\n","  'What date does my Verizon bill come due?',\n","  \"Text Mom to inform her I'm on my way.\",\n","  'I want you to pair my earbuds with my phone.',\n","  'Can you give me the date of the party we are planning for next month?',\n","  'i want an uber to take my family of four to disneyland next weekend.',\n","  'Are there any fees associated with rolling over a 401k to a traditional IRA?',\n","  'I would appreciate it if you could check if I have potatoes on my list. If not, please add them.',\n","  \"no excuses, you're just plain wrong.\",\n","  'Your whisper is so quiet that I can barely hear you. Could you please speak up or use a louder microphone?',\n","  'How many sick days have I taken this year?',\n","  'What is available on my shopping list for dinner tonight?',\n","  'Can you give me an estimate of when I should replace my tires based on their age and mileage?',\n","  \"I'm having trouble hearing you, could you please repeat what you just said?\",\n","  'How does my health insurance work?',\n","  'What is the estimated fuel efficiency of this car on the highway?',\n","  'how many calories are there in a cup of unsweetened almond milk?',\n","  'Can you please put in a PTO request for me from December 15th to December 31st so I can spend quality time with my loved ones during the holidays?',\n","  'How much have I spent on books this quarter?',\n","  \"thanks for being such an awesome friend; you're the best!\",\n","  'how long does it take to make risotto?',\n","  'Did I add buying groceries to my to-do list for this week?',\n","  'Can you tell me about the humidity level in the area?',\n","  'can you give an example of existentialism in practice?',\n","  \"How many PSI's are my tires at the moment?\",\n","  'My TD Bank card has gone missing',\n","  'How can I ensure that I am getting the right type of oil for my vehicle when changing my oil',\n","  'Cancel the reservation for Joe and me right now for the Zephers reservation we had booked.',\n","  'How old is Al?',\n","  \"please add 'Bohemian Rhapsody' to 'Classic Rock'.\",\n","  'I want to start fresh with all settings at their default values.',\n","  \"what's the exchange rate between australian dollars and indian rupees?\",\n","  'how do i prepare a flavorful stir fry dish?',\n","  'Are there any road closures or construction affecting traffic nearby?',\n","  'I am having trouble spelling the word \"sandwich\".',\n","  'Maybe we will find a better solution next week.',\n","  'I would like to cancel my reservation for tonight.',\n","  'How long after I report my card missing will I receive my replacement?',\n","  'Kindly help me cover my medical expenses through my Fidelity account.',\n","  'I am interested in taking a vacation during the last week of June; could you please request it for me?',\n","  \"can you please let me know my medical bill's minimum payment?\",\n","  'Kindly provide me with my credit limit details so I can manage my finances effectively.',\n","  'Do you know where I might have left my phone?',\n","  'My job title is Marketing Manager.',\n","  'can you tell me the interest rate on my cash advance?',\n","  'How do you say \"see you later\" in Korean?',\n","  'Is there a way to expedite the delivery of my W-2 form?',\n","  'how many hours of freedom from work lie ahead of us before our next break?',\n","  'Looking for a cozy spot for dinner tonight. Any ideas?',\n","  \"I'm having trouble locating my phone. Can someone please assist me?\",\n","  'Can I check availability and make a reservation online?',\n","  'Can you please provide the nutritional content of this chocolate bar?',\n","  'Tell me what type of fuel i need to use for this car.',\n","  'What do I need to make a classic paella?',\n","  'How much will it cost to take an Uber from LAX to downtown LA?',\n","  'Your support means everything to me; thank you.',\n","  'I enjoy practicing yoga to relax and rejuvenate myself.',\n","  'At what interval should I get my oil changed to ensure optimal performance of my vehicle?',\n","  'why were you programmed to assist users like me?',\n","  'I want to stay at a hotel in London from April 1st to April 3rd. Can you help me find one?',\n","  'Could you please book a one-way flight from Houston to Chicago on May 15th for under $200',\n","  'do i need a visa to enter the united kingdom if i am from the us?',\n","  \"Can I use my passport to enter the UK if I don't have a visa?\",\n","  'Can you tell me what meetings I have coming up later this week?',\n","  'Can you provide me with the nutritional breakdown of a serving of Greek yogurt?',\n","  'would love some suggestions for a mediterranean feast!',\n","  'I will make sure to book the training room for our 10 am meeting on Monday, so please let me know if that works for everyone',\n","  'What day did I last take my car in for a check-up?',\n","  \"I'm not sure when I'll get around to getting my oil changed next, but I know it's overdue.\",\n","  'unfortunately, my blue debit card was taken without my permission, so I am reporting it as lost.',\n","  'Is my gas tank over half full?',\n","  'Until we meet again; farewell!',\n","  'How long does it typically take to jump-start a car with a dead battery?',\n","  'Can you explain the fees associated with using my card in indonesia?',\n","  'what is the routing number for my us bank account?',\n","  'How many prongs do Italian plugs have?',\n","  'can we give it a more fitting name?',\n","  'Where can I find a decent Indian restaurant in London?',\n","  'I need to know the time in Los Angeles.',\n","  \"I'm impressed by your intelligence; are you a human or a machine?\",\n","  \"It's great chatting with you; do you have feelings too?\",\n","  'Could you please detach my laptop from my phone?',\n","  'Did I send that email yet? Check your sent folder.',\n","  'Can you provide information on the different types of credit cards available in the market?',\n","  'send $50 from joint account to single account'],\n"," 'intent': [124,\n","  74,\n","  119,\n","  106,\n","  129,\n","  107,\n","  102,\n","  19,\n","  146,\n","  9,\n","  17,\n","  132,\n","  131,\n","  89,\n","  140,\n","  56,\n","  65,\n","  12,\n","  70,\n","  86,\n","  25,\n","  34,\n","  15,\n","  125,\n","  63,\n","  117,\n","  24,\n","  135,\n","  109,\n","  35,\n","  70,\n","  24,\n","  118,\n","  42,\n","  99,\n","  4,\n","  71,\n","  26,\n","  97,\n","  78,\n","  141,\n","  76,\n","  83,\n","  68,\n","  128,\n","  74,\n","  126,\n","  104,\n","  41,\n","  110,\n","  86,\n","  43,\n","  7,\n","  94,\n","  79,\n","  55,\n","  41,\n","  144,\n","  139,\n","  20,\n","  48,\n","  48,\n","  44,\n","  2,\n","  90,\n","  1,\n","  44,\n","  67,\n","  109,\n","  111,\n","  58,\n","  33,\n","  138,\n","  103,\n","  88,\n","  138,\n","  18,\n","  27,\n","  126,\n","  66,\n","  26,\n","  69,\n","  96,\n","  53,\n","  52,\n","  83,\n","  33,\n","  45,\n","  31,\n","  60,\n","  141,\n","  28,\n","  144,\n","  29,\n","  39,\n","  107,\n","  62,\n","  11,\n","  59,\n","  13,\n","  43,\n","  93,\n","  105,\n","  73,\n","  123,\n","  145,\n","  110,\n","  127,\n","  14,\n","  123,\n","  37,\n","  49,\n","  128,\n","  22,\n","  18,\n","  61,\n","  121,\n","  133,\n","  9,\n","  82,\n","  115,\n","  85,\n","  51,\n","  14,\n","  90,\n","  108,\n","  72,\n","  80,\n","  0,\n","  136,\n","  0,\n","  116,\n","  95,\n","  19,\n","  38,\n","  54,\n","  75,\n","  131,\n","  120,\n","  40,\n","  116,\n","  96,\n","  76,\n","  100,\n","  23,\n","  30,\n","  58,\n","  67,\n","  137,\n","  3,\n","  22,\n","  147,\n","  84,\n","  149,\n","  27,\n","  118,\n","  120,\n","  122,\n","  65,\n","  101,\n","  5,\n","  29,\n","  95,\n","  1,\n","  17,\n","  92,\n","  143,\n","  47,\n","  119,\n","  102,\n","  51,\n","  113,\n","  31,\n","  77,\n","  94,\n","  21,\n","  66,\n","  105,\n","  11,\n","  122,\n","  52,\n","  148,\n","  32,\n","  111,\n","  79,\n","  146,\n","  8,\n","  2,\n","  16,\n","  32,\n","  134,\n","  10,\n","  80,\n","  98,\n","  30,\n","  101,\n","  57,\n","  142,\n","  106,\n","  36,\n","  114,\n","  87,\n","  87,\n","  15,\n","  10,\n","  112,\n","  81,\n","  72,\n","  142,\n","  92,\n","  46,\n","  133,\n","  93,\n","  50,\n","  75,\n","  62,\n","  34,\n","  16,\n","  130,\n","  6,\n","  6,\n","  100,\n","  64,\n","  91,\n","  68]}"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["train_dict={'utt':train_data, \"intent\":train_int_labels}\n","test_dict={'utt':test_data, \"intent\":test_int_labels}\n","test_dict"]},{"cell_type":"markdown","metadata":{"id":"I68c4JKcePAl"},"source":["#**label encoding- converting labels to numeric values**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j2z1Uyt7UQjK","outputId":"3e26b65a-302f-4eab-eb7c-7b977b602911"},"outputs":[{"data":{"text/plain":["(array([  0,   0,   0, ..., 149, 149, 149]), (2248,))"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.preprocessing import LabelEncoder\n","label_encoder=LabelEncoder()\n","intents_int=label_encoder.fit_transform(intents)\n","intents_int, intents_int.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WpY1ayFpelTN","outputId":"3010d74b-38bd-494a-e274-7daecad93e96"},"outputs":[{"name":"stdout","output_type":"stream","text":["[(0, 'restaurant reviews'), (1, 'definition'), (2, 'next holiday'), (3, 'whisper mode'), (4, 'damaged card')]\n","\n","\n","[('restaurant reviews', 0), ('definition', 1), ('next holiday', 2), ('whisper mode', 3), ('damaged card', 4)]\n"]}],"source":["print(list(id2label.items())[:5])\n","print('\\n')\n","print(list(label2id.items())[:5])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hVOxJ2MuH-62"},"outputs":[],"source":["seed=50\n","torch.manual_seed(seed)\n","num_labels = 150\n","# model_max_length = 64\n","lr=6e-4\n","n_epochs = 30\n","batch_size= 32\n","min_batch_size=2\n","batch_size_c = batch_size / min_batch_size\n","early_stoping_patience = 6 # if valid loss will increase 3 consecutive times with a margin then training will stop.\n","# initial_model = \"xlm-roberta-large\""]},{"cell_type":"markdown","source":["# **Extra Encoder layer**"],"metadata":{"id":"onrcrs1MmPFs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"aKyTiUCG1tH4"},"outputs":[],"source":["n_layers=1\n","d_model = 1024\n","n_heads=1\n","d_k=512\n","d_v=512\n","d_ff=512\n","batch_size_1=min_batch_size\n","hidden_dropout_prob=0.1\n","num_labels=150\n","\n","class GELU(nn.Module):\n","\n","    def forward(self, x):\n","        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n","\n","class Embedding(nn.Module):\n","   def __init__(self):\n","       super(Embedding, self).__init__()\n","       self.tok_embed = nn.Embedding(vocab_size, d_model)  # token embedding\n","       self.pos_embed = nn.Embedding(maxlen, d_model)  # position embedding\n","       self.seg_embed = nn.Embedding(n_segments, d_model)  # segment(token type) embedding\n","       self.norm = nn.LayerNorm(d_model)\n","\n","   def forward(self, x, seg):\n","       seq_len = x.size(1)\n","       pos = torch.arange(seq_len, dtype=torch.long)\n","       pos = pos.unsqueeze(0).expand_as(x)  # (seq_len,) -> (batch_size, seq_len)\n","       embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n","       return self.norm(embedding)\n","\n","class MultiHeadAttention(nn.Module):\n","   def __init__(self):\n","       super(MultiHeadAttention, self).__init__()\n","       self.W_Q = nn.Linear(d_model, d_k * n_heads)\n","       self.W_K = nn.Linear(d_model, d_k * n_heads)\n","       self.W_V = nn.Linear(d_model, d_v * n_heads)\n","       self.linear_layer = nn.Linear(n_heads * d_v, d_model)\n","       self.layer_norm = nn.LayerNorm(d_model)\n","\n","   def forward(self, Q, K, V, attn_mask):\n","       # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n","       residual, batch_size = Q, Q.size(0)\n","       # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n","       q_s = self.W_Q(Q).view(batch_size_1, -1, n_heads, d_k).transpose(1,2)  # q_s: [batch_size x n_heads x len_q x d_k]\n","       k_s = self.W_K(K).view(batch_size_1, -1, n_heads, d_k).transpose(1,2)  # k_s: [batch_size x n_heads x len_k x d_k]\n","       v_s = self.W_V(V).view(batch_size_1, -1, n_heads, d_v).transpose(1,2)  # v_s: [batch_size x n_heads x len_k x d_v]\n","      #  print(attn_mask.shape)\n","       attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1) # attn_mask : [batch_size x n_heads x len_q x len_k]\n","\n","       # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n","       context, attn = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)\n","       context = context.transpose(1, 2).contiguous().view(batch_size_1, -1, n_heads * d_v) # context: [batch_size x len_q x n_heads * d_v]\n","#        print(context.device)\n","\n","       output = self.linear_layer(context)\n","\n","\n","       return self.layer_norm (output + residual), attn # output: [batch_size x len_q x d_model]\n","\n","class PoswiseFeedForwardNet(nn.Module):\n","\n","    def __init__(self, d_model, d_ff):\n","        super(PoswiseFeedForwardNet, self).__init__()\n","        self.l1 = nn.Linear(d_model, d_ff)\n","        self.l2 = nn.Linear(d_ff, d_model)\n","\n","        self.relu = GELU()\n","        self.layer_norm = nn.LayerNorm(d_model)\n","\n","    def forward(self, inputs):\n","        residual = inputs\n","        output = self.l1(inputs)\n","        output = self.relu(output)\n","        output = self.l2(output)\n","        return self.layer_norm(output + residual)\n","\n","class ScaledDotProductAttention(nn.Module):\n","   def __init__(self):\n","       super(ScaledDotProductAttention, self).__init__()\n","\n","   def forward(self, Q, K, V, attn_mask):\n","      #  print(Q.shape)\n","      #  print(K.shape)\n","      #  print(V.shape)\n","      #  print(attn_mask.shape)\n","       scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n","      #  print(scores.shape)\n","      #  print(attn_mask.shape)\n","       attn_mask = attn_mask.bool()\n","      #  print(attn_mask.shape)\n","       scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n","\n","       attn = nn.Softmax(dim=-1)(scores)\n","       context = torch.matmul(attn, V)\n","       return  context, attn\n","\n","class ClassificationHead(nn.Module):\n","    \"\"\"Head for sentence-level classification tasks.\"\"\"\n","\n","    def __init__(self):\n","        super(ClassificationHead,self).__init__()\n","        self.dense = nn.Linear(d_model,d_model)#(config.hidden_size, config.hidden_size)\n","        classifier_dropout = hidden_dropout_prob       #( config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob     )\n","        self.dropout = nn.Dropout(classifier_dropout)\n","        self.out_proj = nn.Linear(d_model,num_labels)#(config.hidden_size, config.num_labels)\n","\n","    def forward(self, features, **kwargs):\n","        x = features[:, 0, :]  # take <s> token (equiv. to [CLS])\n","        x = self.dropout(x)\n","        x = self.dense(x)\n","        x = torch.tanh(x)\n","        x = self.dropout(x)\n","        x = self.out_proj(x)\n","        return x\n","\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self):\n","        super(EncoderLayer, self).__init__()\n","        self.enc_self_attn = MultiHeadAttention()\n","        self.pos_ffn = PoswiseFeedForwardNet(d_model=d_model, d_ff=d_ff)\n","        self.classifier = ClassificationHead()\n","        self.loss_fct = nn.CrossEntropyLoss()\n","\n","    def forward(self, enc_inputs, enc_self_attn_mask,labels):\n","        # print(\"enter\")\n","        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n","        # print(\"enc_outputs, attn \")\n","        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n","        # print(\"enc_outputs ffn\")\n","        logits = self.classifier(enc_outputs)\n","        # print(\"logits\")\n","        loss = self.loss_fct(logits.view(-1, num_labels), labels.view(-1))\n","        # print(\"loss\")\n","        return enc_outputs, attn,logits, loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iD_RAuuFOwbG"},"outputs":[],"source":["encoder_layer = EncoderLayer()"]},{"cell_type":"markdown","metadata":{"id":"8i1CXkqSe-WU"},"source":["# **Loading the pretrained intent classification Roberta large  model by IBM trained on 180 intents and the tokenizer**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LX7u0NH6grN5"},"outputs":[],"source":["# Define the BERT model and tokenizer\n","# keep `ignore_mismatched_sizes=True` so that the classification layer is randomly initialized\n","# model_name = \"cartesinus/bert-base-uncased-amazon-massive-intent\"  # Example: You can replace this with the specific RoBERTa variant you want to use\n","from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n","from transformers import RobertaTokenizer, RobertaForSequenceClassification\n","model_name=\"ibm/roberta-large-vira-intents\"\n","# Initialize the tokenizer\n","tokenizer = RobertaTokenizer.from_pretrained(model_name)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174,"referenced_widgets":["6c7e777ebf0546b8a35caee8265a05de","1da38469b2d248f290b61beed34bf51b","2e44bd7925524c18bc2a8d7dc70e2414","b479b689c7bb4d37934a26a890db3668","59619d6974954c2c8c9531cdef5da78d","eab9be5a1818458f9c58ac55d869f602","f4fab596a3414a3496c5be053e135c6a","c95c0fcb9d7846a4990c2eaf3696cdd5","f16677d41ed243d5ba3fb081d1e58f15","74373c7725784079a8147a35c9ed6006","dfffde77638c4f39b2e9a8b09e25e990","7cb220ea9cfe4af28e9928964d6fe228","1be4e20105c94a8eb77ab2176e4ccf04","51ad77734b2a4ec3b1cf179300ebb737","53bb11af0c7c4ee5a998ff038805bb93","62256d114c2643beb44641e37f5ec3fe","a7ed698342f1433790d090d532a48ae7","ce00ad0ad1b7494fb3627c236cd99008","9a9df57bb74d48af9a21975e27255f19","0979d707e45147b8bc97858e1f94da7c","0c8162d4931444548e5e2fe349623c4e","29996d8060af46e8891b453552c1b5b3"]},"id":"lj0z8YbFobsN","outputId":"796e77a8-6c0f-48fd-a351-bd7ea1f9198c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ibm/roberta-large-vira-intents and are newly initialized because the shapes did not match:\n","- classifier.out_proj.weight: found shape torch.Size([181, 1024]) in the checkpoint and torch.Size([150, 1024]) in the model instantiated\n","- classifier.out_proj.bias: found shape torch.Size([181]) in the checkpoint and torch.Size([150]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Initialize the model\n","num_classes=150\n","# also outputs hidden state and attention state so that new encoder layer can be added after the last hidden state\n","model =RobertaForSequenceClassification.from_pretrained(model_name, num_labels=num_classes, ignore_mismatched_sizes=True,output_hidden_states=True,output_attentions=True)\n","\"\"\"since model have its own id2label mapping and vice versa so, converting them from our id2label and label2id mapping as defined earlier\"\"\"\n","model.label2id=label2id\n","model.id2label=id2label\n"]},{"cell_type":"markdown","source":["# **Getting the Encodings of the text**"],"metadata":{"id":"VlwBzs8Km7Oe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tpfchnW9AH04"},"outputs":[],"source":["def add_encodings(example):\n","  tokenized_inputs = tokenizer(   example['utt'], truncation=True,  is_split_into_words=True   )\n","\n","  # print(tokenized_inputs)\n","  encodings = tokenizer(example[\"utt\"], truncation=True, padding='max_length', is_split_into_words=True)\n","  # print(encodings)\n","  intent=example[\"intent\"]\n","\n","  return { **encodings, 'labels': intent }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["0f33be6444374032bf982fc943570208","8257d4a920b543d7ae452d4a4b7c76bf","b233400f03ff414c89036569bcc5a992","476aaeacb91a4ad9ab6e21b043507eca","81f059c005ce4f9594397bed01308b03","2f0ae954b6254a58a19f25c7a3f8dd43","3817face391e4a9080c20164f99ef89b","3968a4dd73234c5bb4cfcab6dd759cb8","fb867f8d166847b686f361978a3445a6","82f4d5fbf59c4df085c556831e9fec3b","3d6771ee521d4f1aabb3e5dc81e9135e","f9f04c3012394c6d93b546e11845053f"]},"id":"Q5zxnXDPAQcG","outputId":"f0ed3c2c-836b-4e92-cebd-a80dac8f0233"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f9f04c3012394c6d93b546e11845053f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2023 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_dataset =  Dataset.from_dict(train_dict)\n","train_labels = train_dataset['intent']\n","\n","\n","train_dataset = train_dataset.map(add_encodings)#,"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"44eeo196SYzm"},"outputs":[],"source":["# train_dataset[\"attention_mask\"].dtype"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["482e78ae72e2454abc53862e88bbbab5","1f992e2301c348908ac8306963678df7","9f7257c510fd456e9eb1d632fc42a975","fb2919f153f64bf7b164e4aa9497f0ec","5a7c4e2961f148dd89b93c1267362e61","74510ead289c43b88cb39640daf690ee","8415b19ef0d64d968d3ebaaad77c3bf2","25ba00cefbf04c7897653e055415ba07","22c7acfbed0b445f9965af79704b78e1","b4af339e05534238a4bf8f33dbf3507f","4b7ba15c9bdb439e849b41ec6760d905","e14278df69fa45bbb8325d96b6b8547c"]},"id":"D1IQJiilAUuJ","outputId":"28cda8a5-1595-40f0-efc5-3d24e56c4693"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e14278df69fa45bbb8325d96b6b8547c","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/225 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["valid_dataset =  Dataset.from_dict(test_dict)\n","valid_labels = valid_dataset['intent']\n","\n","\n","valid_dataset = valid_dataset.map(add_encodings)#,"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J_a1hQ-mAXji"},"outputs":[],"source":["train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n","valid_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_BjMOYViLwBR","outputId":"9f87e593-053b-47ac-ae03-8bf54b0636c2"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['utt', 'intent', 'input_ids', 'attention_mask', 'labels'],\n","    num_rows: 225\n","})"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["valid_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1LGL0lZ2AZ6y"},"outputs":[],"source":["train_data = torch.utils.data.DataLoader(train_dataset, batch_size=min_batch_size)\n","valid_data = torch.utils.data.DataLoader(valid_dataset, batch_size=min_batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r24ftzv6AcH9","outputId":"5f0e4464-85a5-41b4-e2fc-8a20a6edf220"},"outputs":[{"name":"stdout","output_type":"stream","text":["1012\n","<torch.utils.data.dataloader.DataLoader object at 0x7f55357e8f10>\n","113\n","<torch.utils.data.dataloader.DataLoader object at 0x7f55357e8b20>\n"]}],"source":["# Number of batches for each data\n","print(len(train_data))\n","print(train_data)\n","print(len(valid_data))\n","print(valid_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oWSO2gUcAe5O","outputId":"eabfa192-7cba-4405-9fc0-7441c09c0779"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["#check cuda or cpu\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pB_yoigrKhP0","outputId":"f87dc94c-0567-4b1d-f029-1bb7e31df0d6"},"outputs":[{"data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n","      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-23): 24 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=1024, out_features=150, bias=True)\n","  )\n",")"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["model.parameters()\n","model.to(device) # pushing model to cuda(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BaghWcroQiu_","outputId":"eb186fa6-1a12-42e0-f5c1-59ce1f849b80"},"outputs":[{"data":{"text/plain":["EncoderLayer(\n","  (enc_self_attn): MultiHeadAttention(\n","    (W_Q): Linear(in_features=1024, out_features=512, bias=True)\n","    (W_K): Linear(in_features=1024, out_features=512, bias=True)\n","    (W_V): Linear(in_features=1024, out_features=512, bias=True)\n","    (linear_layer): Linear(in_features=512, out_features=1024, bias=True)\n","    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (pos_ffn): PoswiseFeedForwardNet(\n","    (l1): Linear(in_features=1024, out_features=512, bias=True)\n","    (l2): Linear(in_features=512, out_features=1024, bias=True)\n","    (relu): GELU()\n","    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (classifier): ClassificationHead(\n","    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=1024, out_features=150, bias=True)\n","  )\n","  (loss_fct): CrossEntropyLoss()\n",")"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["encoder_layer.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IqHgxN5dLwBR","outputId":"c59dce75-6540-48e0-9c1c-98462b92266f"},"outputs":[{"data":{"text/plain":["EncoderLayer(\n","  (enc_self_attn): MultiHeadAttention(\n","    (W_Q): Linear(in_features=1024, out_features=512, bias=True)\n","    (W_K): Linear(in_features=1024, out_features=512, bias=True)\n","    (W_V): Linear(in_features=1024, out_features=512, bias=True)\n","    (linear_layer): Linear(in_features=512, out_features=1024, bias=True)\n","    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (pos_ffn): PoswiseFeedForwardNet(\n","    (l1): Linear(in_features=1024, out_features=512, bias=True)\n","    (l2): Linear(in_features=512, out_features=1024, bias=True)\n","    (relu): GELU()\n","    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (classifier): ClassificationHead(\n","    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=1024, out_features=150, bias=True)\n","  )\n","  (loss_fct): CrossEntropyLoss()\n",")"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["encoder_layer"]},{"cell_type":"markdown","source":["# **Training the model**"],"metadata":{"id":"P3Hrv6zvnKLY"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":154,"referenced_widgets":["34040c8db9e6492a8520735648e30f28","fa9bb7e7488346f496ac3a621b76c9f5","d30b29e490b243c6b39b2e2203273ecd","6062b129318d4292a63ba645c9497707","8c09eb63a13048c6b2c530a06892dcc6","5a335430c78b49c9bbac23d13bd86674","5932a87e59ae47a18f9e6c9c3152e45b","fbdd11048bf5449d87f38b45da39e346","504cdd40c7b64bcab7b08587f6d4c159","8c93b0723efb4d3aab4f224c2b54f4dc","2573a76065fa401fbd3ff323393ca385","fa3861f29a6f4461acf360befbde3e97","0342e77d31ad4d269967cdbb9ceeeb56","0415ddd5313d471384e01b64a1a37c8d","3bce42f2b3d0446fa85dc88433d1b686","8b15a7456cd2469cab43c7974a4eaf46","23572dde8465498cb71ec536d5e49b77","de4a953fd40c45739c68e1f44ced6bac","6da70b0cf3b44170b45fe4a7d40c2889","25bf41dec77a406288b504f4cd666d32","e3b2deafde824e219a6d9a8db1d31a67","b2bc305d573b4b6c9f2d0a0697dda706","07da29da80e84ed8bed67a25806a6220","1c650c1a45a342a0834a4a104f7b7fb2","3a4c841490bd46178bc664f77d19b9e0","5b0fd0aa36624cb4923d1bf9bf873be5","360619a67443440194e1e8d78938ddb6","c6bcd9c5160d49cc95e1f93951fdf2ce","1c6f31644f284b84a417b214d57a2544","7ff5f98c7e7742289ea17d09c740d0b6","3b439004594b4048a651e822221da536","6f9e16c84d04458ebe9b5afde547572d","12ebb123396b4ad197383afa70976880","18cf60e00bce42bfb717b73741c1ef20","0c909c2e50284fc9a462c6d44b580faa","7e29c52a9ae649aa974f6ed21eb9be05","b7bdcf118d674bb396aa7672a9540596","6d7dabf408cc4b2f90bdf5c596165202","daff14f8070f409183369017f9f09eec","e9ab5435dc284eddba7f772f3450e414","6e53c2053c544630a79200f1d5ccaff9","42c0d5a1849a4ff7a8328c95f004122b","da2099906a824a2a9eb2a5492a2b8d97","03a0929f30a748c7831e3702cdc21221","a3cdb7d2db534ccea9e332245941aac3","84462ee28bc64eed9eda523ddbdd0d46","2f45ab552f624d378d4c15d70f4ce2b4","74b7a5a5cfac41e5b730987c24345a79"]},"id":"EJcZi8gkAk2Z","outputId":"d74d298a-83f7-4b23-e53d-8586a125e096"},"outputs":[{"name":"stdout","output_type":"stream","text":["training start\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07da29da80e84ed8bed67a25806a6220","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/30 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["0\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1c650c1a45a342a0834a4a104f7b7fb2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1012 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(5.0678, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(4.8293, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(3.3078, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.8448, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.1009, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.7810, device='cuda:0', grad_fn=<NllLossBackward0>)\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/ files saved\n","total_loss 82.2145941236522\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a4c841490bd46178bc664f77d19b9e0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/113 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0744, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.7283, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.2777, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(3.9151, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.3336, device='cuda:0', grad_fn=<NllLossBackward0>)\n","valid_total_loss  3.184286670992151\n","1\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b0fd0aa36624cb4923d1bf9bf873be5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1012 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.1719, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.7514, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.7294, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.5341, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.4976, device='cuda:0', grad_fn=<NllLossBackward0>)\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/ files saved\n","total_loss 22.468319865409285\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"360619a67443440194e1e8d78938ddb6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/113 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0441, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.4930, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0783, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(2.4732, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.1127, device='cuda:0', grad_fn=<NllLossBackward0>)\n","valid_total_loss  2.1744741839938797\n","2\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6bcd9c5160d49cc95e1f93951fdf2ce","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1012 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.1357, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.1999, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.1499, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.1371, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0116, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.2782, device='cuda:0', grad_fn=<NllLossBackward0>)\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/ files saved\n","total_loss 10.444302194140619\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1c6f31644f284b84a417b214d57a2544","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/113 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.4120, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0458, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(2.8066, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0272, device='cuda:0', grad_fn=<NllLossBackward0>)\n","valid_total_loss  2.288058840567828\n","3\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ff5f98c7e7742289ea17d09c740d0b6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1012 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.1072, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.2893, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.1348, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0384, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0731, device='cuda:0', grad_fn=<NllLossBackward0>)\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/ files saved\n","total_loss 6.396931607654551\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b439004594b4048a651e822221da536","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/113 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.3662, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0317, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(3.0591, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n","valid_total_loss  2.2027516499510966\n","4\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f9e16c84d04458ebe9b5afde547572d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1012 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0308, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.3289, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0256, device='cuda:0', grad_fn=<NllLossBackward0>)\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/ files saved\n","total_loss 4.161131309934717\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12ebb123396b4ad197383afa70976880","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/113 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0500, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.2012, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0211, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(2.5421, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n","valid_total_loss  2.069925582385622\n","5\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18cf60e00bce42bfb717b73741c1ef20","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1012 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0098, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0405, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0227, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0475, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0341, device='cuda:0', grad_fn=<NllLossBackward0>)\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/ files saved\n","total_loss 4.100042094294622\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c909c2e50284fc9a462c6d44b580faa","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/113 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0334, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.6591, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0134, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(2.1352, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward0>)\n","valid_total_loss  2.113439850290888\n","6\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e29c52a9ae649aa974f6ed21eb9be05","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1012 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.1518, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0528, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0216, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0227, device='cuda:0', grad_fn=<NllLossBackward0>)\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/ files saved\n","total_loss 3.39022092939922\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b7bdcf118d674bb396aa7672a9540596","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/113 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0317, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.6640, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.9957, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0105, device='cuda:0', grad_fn=<NllLossBackward0>)\n","valid_total_loss  2.0377220390655566\n","7\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d7dabf408cc4b2f90bdf5c596165202","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1012 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.1214, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.1705, device='cuda:0', grad_fn=<NllLossBackward0>)\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/ files saved\n","total_loss 3.159013738757494\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"daff14f8070f409183369017f9f09eec","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/113 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.2179, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.1233, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.3603, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n","valid_total_loss  1.8893073556064337\n","8\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e9ab5435dc284eddba7f772f3450e414","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1012 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0223, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0184, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.1809, device='cuda:0', grad_fn=<NllLossBackward0>)\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/ files saved\n","total_loss 3.841177355061518\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e53c2053c544630a79200f1d5ccaff9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/113 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0593, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0237, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(2.1286, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0435, device='cuda:0', grad_fn=<NllLossBackward0>)\n","valid_total_loss  2.2790772258995275\n","9\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42c0d5a1849a4ff7a8328c95f004122b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1012 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0211, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0247, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/ files saved\n","total_loss 2.824882695225824\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da2099906a824a2a9eb2a5492a2b8d97","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/113 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.1075, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0168, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(2.3551, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n","valid_total_loss  1.9960842881264398\n","10\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03a0929f30a748c7831e3702cdc21221","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1012 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0235, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0285, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0188, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/ files saved\n","total_loss 2.5139362949539645\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3cdb7d2db534ccea9e332245941aac3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/113 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(1.6201, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0253, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(2.2627, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n","valid_total_loss  2.2625160262032296\n","11\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84462ee28bc64eed9eda523ddbdd0d46","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1012 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0252, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/ files saved\n","total_loss 2.26468389922411\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f45ab552f624d378d4c15d70f4ce2b4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/113 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(3.1071, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0238, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(2.2500, device='cuda:0', grad_fn=<NllLossBackward0>)\n","tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n","valid_total_loss  2.2309623442397424\n","12\n","/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0006_32_30seed50/\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74b7a5a5cfac41e5b730987c24345a79","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1012 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n"]}],"source":["#run this cell only for training\n","\n","num_training_steps = n_epochs * len(train_data)#/batch_size\n","\n","optimizer = optim.AdamW(params=encoder_layer.parameters(), lr=lr)\n","lr_scheduler = get_scheduler(name=\"linear\", optimizer=optimizer, num_warmup_steps=5, num_training_steps=num_training_steps)\n","\n","print(\"training start\")\n","\n","\n","previous_total_valid_loss = sys.float_info.max\n","valid_min_loss = previous_total_valid_loss\n","early_stoping_flag=0\n","train_loss_epoch=[]\n","valid_loss_epoch=[]\n","# Directory where all the weights of model will get saved(Checkpoint)\n","directory = \"/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm\"+str(lr)+\"_\"+str(batch_size)+\"_\"+str(n_epochs)+\"seed\"+str(seed)+\"/\"\n","# iterate through the data 'n_epochs' times\n","for epoch in tqdmn(range(n_epochs)):\n","    # set the model in 'train' mode and send it to the device\n","    model.to(device)#.train()\n","    encoder_layer.train().to(device)\n","    print(epoch)\n","    print(directory)\n","\n","\n","    train_loss = []\n","    current_loss = 0\n","    total_loss=0\n","    # iterate through each batch of t    he train data\n","    for i, batch in enumerate(tqdmn(train_data)):\n","\n","        # move the batch tensors to the same device as the\n","        batch = { k: v.to(device) for k, v in batch.items() }\n","        # print(batch[\"float_tensor\"].dtype)\n","        batch[\"attention_mask\"]=batch[\"attention_mask\"].unsqueeze(1)\n","#         print(len(batch[\"attention_mask\"]))\n","        batch[\"attention_mask\"] = batch[\"attention_mask\"].expand(len(batch[\"attention_mask\"]), d_k, d_k).to(device)\n","        # print(batch[\"attention_mask\"].shape)#.unsqueeze(1)\n","\n","\n","#         print(batch[\"labels\"].dtype)\n","#         print(\"*\")\n","#         print(len(batch[\"attention_mask\"]))\n","#         print(len(batch[\"input_ids\"]))\n","#         print(len(batch[\"labels\"]))\n","\n","        if len(batch[\"labels\"]) == min_batch_size :\n","            # send 'input_ids', 'attention_mask' and 'labels' to the model\n","            outputs = model.forward(**batch)\n","            # print(outputs)\n","            enc_outputs, attn, logits, loss = encoder_layer(outputs.hidden_states[24],batch[\"attention_mask\"] , batch[\"labels\"])#**batch outputs.attentions[23]\n","            if i%200 ==0:\n","                print(loss)\n","\n","            # the outputs are of shape (loss, logits)\n","            #print(outputs[1])\n","\n","\n","            # loss = outputs[0]\n","\n","            #print(\"loss\",loss)\n","            loss.backward()\n","\n","\n","            current_loss += loss.item()\n","\n","            if i % batch_size_c == 0 and i > 0: #if i >= 0:  # #           #if i % 8 == 0 and i > 0:\n","                # update the model using the optimizer\n","                optimizer.step()\n","                lr_scheduler.step()\n","                # once we update the model we set the gradients to zero\n","                optimizer.zero_grad()\n","                # store the loss value for visualization\n","                train_loss.append(current_loss/batch_size)\n","                total_loss=total_loss + current_loss/batch_size\n","                current_loss = 0\n","    train_loss_epoch.append(total_loss)\n","    # update the model one last time for this epoch\n","    optimizer.step()\n","    lr_scheduler.step()\n","    optimizer.zero_grad()\n","\n","    print(directory + ' files saved')\n","    print('total_loss',total_loss)\n","    model.save_pretrained(directory+\"best_e_\"+str(epoch))\n","    torch.save(encoder_layer.state_dict(), directory+\"best_e_enl\"+str(epoch)+'entire_model.pth')\n","#     torch.save(encoder_layer, directory+\"best_e_enl\"+str(epoch)+'entire_model.pth')\n","    #####################################################################################################3\n","#     validation\n","\n","    model.eval().to(device)\n","    encoder_layer.eval().to(device)\n","    valid_loss = []\n","    valid_current_loss = 0\n","    valid_total_loss=0\n","\n","    # iterate through each batch of t    he train data\n","    for i, batch in enumerate(tqdmn(valid_data)):\n","\n","        # move the batch tensors to the same device as the\n","        batch = { k: v.to(device) for k, v in batch.items() }\n","        # send 'input_ids', 'attention_mask' and 'labels' to the model\n","        batch[\"attention_mask\"]=batch[\"attention_mask\"].unsqueeze(1)\n","#         print(len(batch[\"attention_mask\"]))\n","        batch[\"attention_mask\"] = batch[\"attention_mask\"].expand(len(batch[\"attention_mask\"]), d_k, d_k).to(device)\n","\n","        if len(batch[\"labels\"]) == min_batch_size :\n","            outputs = model(**batch)\n","            # the outputs are of shape (loss, logits)\n","            #print(outputs[1])\n","    #         print(\"*\")\n","    #         print(batch[\"attention_mask\"].shape)\n","    #         print(len(batch[\"attention_mask\"]))\n","    #         print(len(batch[\"input_ids\"]))\n","    #         print(len(batch[\"labels\"]))\n","\n","            enc_outputs, attn, logits, loss = encoder_layer(outputs.hidden_states[24],batch[\"attention_mask\"] , batch[\"labels\"])#**batch outputs.attentions[23]\n","#             print(loss)\n","\n","\n","            # loss = outputs[0]\n","            #print(\"loss\",loss)\n","\n","            if i%25 ==0:\n","                print(loss)\n","            valid_current_loss += loss.item()\n","            #print(valid_current_loss)\n","\n","            if i % batch_size_c == 0 and i > 0: #depend on batch size and GPU\n","\n","                valid_loss.append(valid_current_loss/batch_size)\n","                valid_total_loss=valid_total_loss + valid_current_loss/batch_size\n","                valid_current_loss = 0\n","                #print(\"valid_total_loss \",valid_total_loss)\n","\n","    print(\"valid_total_loss \",valid_total_loss)\n","    valid_loss_epoch.append(valid_total_loss)\n","    if valid_total_loss < valid_min_loss:\n","        valid_min_loss = valid_total_loss\n","#         model.save_pretrained(directory+\"best_e_\"+str(epoch))\n","\n","\n","    if previous_total_valid_loss < valid_total_loss:\n","        early_stoping_flag += 1\n","    else:\n","        early_stoping_flag=0\n","    previous_total_valid_loss = valid_total_loss\n","\n","\n","    if early_stoping_flag == early_stoping_patience:\n","        print(\"early_stoping occure\")\n","        break\n","\n","\n","\n","print('training complete')\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jbQeC7J9gtpP"},"source":["# **For prediction at test data **\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Or5KI6eWLwBS"},"outputs":[],"source":["# Prediction\n","def  prediction(best_model_path,best_encoder_path, eval_data):\n","\n","    predicted=[]\n","    tokanised_exam=[]\n","    true_labels=[]\n","\n","    predicted_for_classification_report=[]\n","\n","    ##################################################\n","    #load best model\n","\n","\n","    print(best_model_path)\n","\n","    model = RobertaForSequenceClassification.from_pretrained(best_model_path)\n","    model = model.eval().to(device)\n","\n","    encoder_layer =EncoderLayer()\n","\n","    encoder_layer=encoder_layer.to(device)\n","    encoder_layer.load_state_dict(torch.load(best_encoder_path))\n","    encoder_layer.eval()\n","    print(\"model device\")\n","    # batch the train data so that each batch contains 4 examples (using 'batch_size')\n","    #test_data = torch.utils.data.DataLoader(test_dataset, batch_size=16)\n","\n","    eval_data = eval_data\n","\n","\n","\n","    # iterate through each batch of the eval data\n","    for i, batch in enumerate(tqdmn(eval_data)):\n","\n","\n","\n","       # move the batch tensors to the same device as the\n","        batch = { k: v.to(device) for k, v in batch.items() }\n","        # send 'input_ids', 'attention_mask' and 'labels' to the model\n","        batch[\"attention_mask\"]=batch[\"attention_mask\"].unsqueeze(1)\n","#         print(len(batch[\"attention_mask\"]))\n","        batch[\"attention_mask\"] = batch[\"attention_mask\"].expand(len(batch[\"attention_mask\"]), d_k, d_k).to(device)\n","\n","        if len(batch[\"labels\"]) == min_batch_size :\n","            outputs = model(**batch)\n","            print(outputs.hidden_states[24].shape)\n","            # the outputs are of shape (loss, logits)\n","            #print(outputs[1])\n","    #         print(\"*\")\n","    #         print(batch[\"attention_mask\"].shape)\n","    #         print(len(batch[\"attention_mask\"]))\n","    #         print(len(batch[\"input_ids\"]))\n","    #         print(len(batch[\"labels\"]))\n","\n","            enc_outputs, attn, logits, loss = encoder_layer(outputs.hidden_states[24],batch[\"attention_mask\"] , batch[\"labels\"])#**batch outputs.attentions[23]\n","#             print(loss)\n","\n","        print(logits.shape)\n","        # iterate through the examples\n","\n","        # Apply softmax to get class probabilities\n","#         probabilities = torch.softmax(logits, dim=1)\n","\n","        # Get the predicted class (index with the highest probability)\n","        pred_values = torch.argmax(logits, dim=1)\n","        pred_values = pred_values.tolist()\n","        predicted.append(pred_values)\n","\n","        true_values = batch['labels']\n","        print(true_values.shape)\n","        true_labels.extend(true_values.tolist())\n","\n","        predicted_for_classification_report.extend(pred_values)\n","\n","\n","          # go through all true and predicted values and store them in the confusion matrix\n","          # for true, pred in zip(true_values, pred_values):\n","          #     confusion[true.item()][pred.item()] += 1\n","    print(predicted_for_classification_report)\n","    return predicted, predicted_for_classification_report\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uuOPc7yzLwBT"},"outputs":[],"source":["#**Put path of best checkponts saved during training**\n","best_encoder_path=\"/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0001_32_22seed55/best_e_enl2entire_model.pth\"\n","\n","best_model_path=\"/home/naive123/nlp/Sumit/massive/model_1_extra_layer/roberta_ibm0.0001_32_22seed55/best_e_2/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CVswAZ80LwBT"},"outputs":[],"source":["predicted, predicted_for_classification_report = prediction(best_model_path, best_encoder_path,valid_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jsk9IZw9LwBT"},"outputs":[],"source":["len(predicted_for_classification_report)\n","# target_names = labels_list\n","from sklearn.metrics import classification_report\n","print(classification_report(test_labels, predicted_labels[:-1]))#,labels=[i for i in range(150)]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0W9MKYyILwBT"},"outputs":[],"source":["len(test_labels)\n","test_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VbcemlO_LwBT"},"outputs":[],"source":["predicted_labels=[id2label[i] for i in predicted_for_classification_report]\n","predicted_labels"]},{"cell_type":"markdown","metadata":{"id":"x7QIn5yAmVMC"},"source":["# **making pytorch datasets**"]},{"cell_type":"markdown","metadata":{"id":"y-y9Zc0lnhBV"},"source":["# **Blind dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vh0Sis-LqxbX"},"outputs":[],"source":["test_list[:20]"]},{"cell_type":"markdown","metadata":{"id":"njGM6e6Dm2t5"},"source":["# **loading the tokenizer for predicting labels on blind dataset(whose labels not available)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vL4kALMeixO-"},"outputs":[],"source":["from transformers import AutoTokenizer\n","tokenizer=AutoTokenizer.from_pretrained(model_name)\n","test_text = [item[\"utt\"] for item in test_list]\n","\n","# Tokenize the test data\n","test_set_encodings = tokenizer(test_text, padding=True, truncation=True, return_tensors=\"pt\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nZVf-2ntnQFz"},"outputs":[],"source":["test_set_encodings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q0UI8QJXpNQY"},"outputs":[],"source":["\"\"\"Dataloader and Also Dataset to convert the testing(blind) dataset featues(encodings) obtained from the tokenizer into the format suitable for the training\"\"\"\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Convert the encodings into tensors\n","input_ids = test_set_encodings['input_ids']\n","attention_mask = test_set_encodings['attention_mask']\n","# token_type_ids = test_set_encodings['token_type_ids']\n","\n","# Create a TensorDataset\n","test_dataset = TensorDataset(input_ids, attention_mask,)\n","\n","# Define batch size\n","batch_size = 32\n","\n","# Create a DataLoader\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n"]},{"cell_type":"markdown","metadata":{"id":"8H4BFlCwnZFR"},"source":["# **prediction at blind test data set**"]},{"cell_type":"code","source":["predicted, predicted_for_classification_report = prediction(best_model_path, best_encoder_path,test_dataloader)"],"metadata":{"id":"eEzDVyHFyOyZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EKJecWAEwJts"},"source":["# **Preparing For submission format**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4qxKttirzcc2"},"outputs":[],"source":["predicted_labels_test=[id2label[int(id)] for id in list(predictions)]\n","predicted_labels_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-vtNj83lBGI"},"outputs":[],"source":["import pandas as pd\n","my_id=[]\n","my_intent1=[]\n","\n","my_dict1={}\n","for i, entry in enumerate(test_list):\n","    my_id.append({'indoml_id':i+1,'intent':predicted_labels_test[i]})\n","    my_intent1.append(predicted_labels_test[i])\n","    my_dict1['id']=my_id\n","    my_dict1['intent1']=my_intent1\n","#     temp={}\n","#     temp['indoml_id']=entry['locale']+'/'+entry['id']\n","#     temp['intent']=entry['pred_intent']\n","#     my_dict['k']=temp\n","#     k+=1\n","my_dict1_pd=pd.DataFrame.from_dict(my_dict1)\n","my_dict1_pd.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BsvMGqXRxTR4"},"outputs":[],"source":["with open('output.predict', 'w') as out_file:\n","    for entry in my_dict1_pd['id']:\n","        out_file.write(str(entry))\n","        out_file.write('\\n')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p-7TsDHxxKUi"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"massive_1","language":"python","name":"massive_1"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0342e77d31ad4d269967cdbb9ceeeb56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23572dde8465498cb71ec536d5e49b77","placeholder":"â","style":"IPY_MODEL_de4a953fd40c45739c68e1f44ced6bac","value":"  0%"}},"0415ddd5313d471384e01b64a1a37c8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_6da70b0cf3b44170b45fe4a7d40c2889","max":1012,"min":0,"orientation":"horizontal","style":"IPY_MODEL_25bf41dec77a406288b504f4cd666d32","value":1}},"0979d707e45147b8bc97858e1f94da7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c8162d4931444548e5e2fe349623c4e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f33be6444374032bf982fc943570208":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8257d4a920b543d7ae452d4a4b7c76bf","IPY_MODEL_b233400f03ff414c89036569bcc5a992","IPY_MODEL_476aaeacb91a4ad9ab6e21b043507eca"],"layout":"IPY_MODEL_81f059c005ce4f9594397bed01308b03"}},"1be4e20105c94a8eb77ab2176e4ccf04":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7ed698342f1433790d090d532a48ae7","placeholder":"â","style":"IPY_MODEL_ce00ad0ad1b7494fb3627c236cd99008","value":"Downloading pytorch_model.bin: 100%"}},"1da38469b2d248f290b61beed34bf51b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eab9be5a1818458f9c58ac55d869f602","placeholder":"â","style":"IPY_MODEL_f4fab596a3414a3496c5be053e135c6a","value":"Downloading (â¦)lve/main/config.json: 100%"}},"1f992e2301c348908ac8306963678df7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74510ead289c43b88cb39640daf690ee","placeholder":"â","style":"IPY_MODEL_8415b19ef0d64d968d3ebaaad77c3bf2","value":"Map: 100%"}},"22c7acfbed0b445f9965af79704b78e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23572dde8465498cb71ec536d5e49b77":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2573a76065fa401fbd3ff323393ca385":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25ba00cefbf04c7897653e055415ba07":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25bf41dec77a406288b504f4cd666d32":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"29996d8060af46e8891b453552c1b5b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e44bd7925524c18bc2a8d7dc70e2414":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c95c0fcb9d7846a4990c2eaf3696cdd5","max":1520,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f16677d41ed243d5ba3fb081d1e58f15","value":1520}},"2f0ae954b6254a58a19f25c7a3f8dd43":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34040c8db9e6492a8520735648e30f28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa9bb7e7488346f496ac3a621b76c9f5","IPY_MODEL_d30b29e490b243c6b39b2e2203273ecd","IPY_MODEL_6062b129318d4292a63ba645c9497707"],"layout":"IPY_MODEL_8c09eb63a13048c6b2c530a06892dcc6"}},"3817face391e4a9080c20164f99ef89b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3968a4dd73234c5bb4cfcab6dd759cb8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bce42f2b3d0446fa85dc88433d1b686":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3b2deafde824e219a6d9a8db1d31a67","placeholder":"â","style":"IPY_MODEL_b2bc305d573b4b6c9f2d0a0697dda706","value":" 1/1012 [00:49&lt;13:50:54, 49.31s/it]"}},"3d6771ee521d4f1aabb3e5dc81e9135e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"476aaeacb91a4ad9ab6e21b043507eca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82f4d5fbf59c4df085c556831e9fec3b","placeholder":"â","style":"IPY_MODEL_3d6771ee521d4f1aabb3e5dc81e9135e","value":" 2023/2023 [00:01&lt;00:00, 1850.27 examples/s]"}},"482e78ae72e2454abc53862e88bbbab5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f992e2301c348908ac8306963678df7","IPY_MODEL_9f7257c510fd456e9eb1d632fc42a975","IPY_MODEL_fb2919f153f64bf7b164e4aa9497f0ec"],"layout":"IPY_MODEL_5a7c4e2961f148dd89b93c1267362e61"}},"4b7ba15c9bdb439e849b41ec6760d905":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"504cdd40c7b64bcab7b08587f6d4c159":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"51ad77734b2a4ec3b1cf179300ebb737":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a9df57bb74d48af9a21975e27255f19","max":2239767213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0979d707e45147b8bc97858e1f94da7c","value":2239767213}},"53bb11af0c7c4ee5a998ff038805bb93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c8162d4931444548e5e2fe349623c4e","placeholder":"â","style":"IPY_MODEL_29996d8060af46e8891b453552c1b5b3","value":" 2.24G/2.24G [00:26&lt;00:00, 112MB/s]"}},"5932a87e59ae47a18f9e6c9c3152e45b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59619d6974954c2c8c9531cdef5da78d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a335430c78b49c9bbac23d13bd86674":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a7c4e2961f148dd89b93c1267362e61":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6062b129318d4292a63ba645c9497707":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c93b0723efb4d3aab4f224c2b54f4dc","placeholder":"â","style":"IPY_MODEL_2573a76065fa401fbd3ff323393ca385","value":" 0/10 [00:00&lt;?, ?it/s]"}},"62256d114c2643beb44641e37f5ec3fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c7e777ebf0546b8a35caee8265a05de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1da38469b2d248f290b61beed34bf51b","IPY_MODEL_2e44bd7925524c18bc2a8d7dc70e2414","IPY_MODEL_b479b689c7bb4d37934a26a890db3668"],"layout":"IPY_MODEL_59619d6974954c2c8c9531cdef5da78d"}},"6da70b0cf3b44170b45fe4a7d40c2889":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74373c7725784079a8147a35c9ed6006":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74510ead289c43b88cb39640daf690ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cb220ea9cfe4af28e9928964d6fe228":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1be4e20105c94a8eb77ab2176e4ccf04","IPY_MODEL_51ad77734b2a4ec3b1cf179300ebb737","IPY_MODEL_53bb11af0c7c4ee5a998ff038805bb93"],"layout":"IPY_MODEL_62256d114c2643beb44641e37f5ec3fe"}},"81f059c005ce4f9594397bed01308b03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8257d4a920b543d7ae452d4a4b7c76bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f0ae954b6254a58a19f25c7a3f8dd43","placeholder":"â","style":"IPY_MODEL_3817face391e4a9080c20164f99ef89b","value":"Map: 100%"}},"82f4d5fbf59c4df085c556831e9fec3b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8415b19ef0d64d968d3ebaaad77c3bf2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b15a7456cd2469cab43c7974a4eaf46":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c09eb63a13048c6b2c530a06892dcc6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c93b0723efb4d3aab4f224c2b54f4dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a9df57bb74d48af9a21975e27255f19":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f7257c510fd456e9eb1d632fc42a975":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25ba00cefbf04c7897653e055415ba07","max":225,"min":0,"orientation":"horizontal","style":"IPY_MODEL_22c7acfbed0b445f9965af79704b78e1","value":225}},"a7ed698342f1433790d090d532a48ae7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b233400f03ff414c89036569bcc5a992":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3968a4dd73234c5bb4cfcab6dd759cb8","max":2023,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb867f8d166847b686f361978a3445a6","value":2023}},"b2bc305d573b4b6c9f2d0a0697dda706":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b479b689c7bb4d37934a26a890db3668":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74373c7725784079a8147a35c9ed6006","placeholder":"â","style":"IPY_MODEL_dfffde77638c4f39b2e9a8b09e25e990","value":" 1.52k/1.52k [00:00&lt;00:00, 14.8kB/s]"}},"b4af339e05534238a4bf8f33dbf3507f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c95c0fcb9d7846a4990c2eaf3696cdd5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce00ad0ad1b7494fb3627c236cd99008":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d30b29e490b243c6b39b2e2203273ecd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbdd11048bf5449d87f38b45da39e346","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_504cdd40c7b64bcab7b08587f6d4c159","value":0}},"de4a953fd40c45739c68e1f44ced6bac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfffde77638c4f39b2e9a8b09e25e990":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3b2deafde824e219a6d9a8db1d31a67":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eab9be5a1818458f9c58ac55d869f602":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f16677d41ed243d5ba3fb081d1e58f15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4fab596a3414a3496c5be053e135c6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa3861f29a6f4461acf360befbde3e97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0342e77d31ad4d269967cdbb9ceeeb56","IPY_MODEL_0415ddd5313d471384e01b64a1a37c8d","IPY_MODEL_3bce42f2b3d0446fa85dc88433d1b686"],"layout":"IPY_MODEL_8b15a7456cd2469cab43c7974a4eaf46"}},"fa9bb7e7488346f496ac3a621b76c9f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a335430c78b49c9bbac23d13bd86674","placeholder":"â","style":"IPY_MODEL_5932a87e59ae47a18f9e6c9c3152e45b","value":"  0%"}},"fb2919f153f64bf7b164e4aa9497f0ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4af339e05534238a4bf8f33dbf3507f","placeholder":"â","style":"IPY_MODEL_4b7ba15c9bdb439e849b41ec6760d905","value":" 225/225 [00:00&lt;00:00, 1532.54 examples/s]"}},"fb867f8d166847b686f361978a3445a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fbdd11048bf5449d87f38b45da39e346":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}