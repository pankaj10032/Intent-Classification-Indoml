{"cells":[{"cell_type":"markdown","metadata":{"id":"E-OaLrjOvAP3"},"source":["# **Downloading the dependencies**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XOvfSP9gvAP8","outputId":"2bd3517c-2795-49f4-d605-a7320cf389d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"markdown","source":["# **Connecting google colab to drive**"],"metadata":{"id":"COar6kq8vETt"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pz7WesrSvDr_","outputId":"9675dc56-71ca-485f-bf24-ef5a3795c0f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"bYSVMm9JvAP9"},"source":["# **Importing the necessary modules**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-GwjyIugvAP-"},"outputs":[],"source":["import json\n","import pandas as pd\n","import os\n","import torch\n","from transformers import RobertaTokenizer, RobertaForSequenceClassification\n","from torch.utils.data import DataLoader, TensorDataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iooZvgNqvAP-"},"outputs":[],"source":["device=torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","num_classe=150"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hBXbEu-wvAP-"},"outputs":[],"source":["def test(model_path, data_path):\n","    solution_file_path=os.path.join(data_path,'surprise.solution')\n","    test_data_path=os.path.join(data_path,'massive_test.data')\n","    # loading surprise.solution file for getting id2label and label2id mapping\n","    with open(solution_file_path,'r') as solutions_file:\n","        solutions=[json.loads(line) for line in solutions_file] # reading json data from data_path and parse it into a test_data list\n","\n","    labels_list=[]\n","    for label in solutions:\n","        labels_list.append(label['intent'])\n","    unique_labels_list=[]\n","    for x in labels_list:\n","        if x not in unique_labels_list:\n","            unique_labels_list.append(x)\n","    # unique_labels_list, len(unique_labels_list)\n","\n","    label2id={}\n","    id2label={}\n","    for i, label in enumerate(unique_labels_list):\n","        label2id[label]=i\n","        id2label[i]=label\n","    # print(list(id2label.items())[:5])\n","    # print('\\n')\n","    # print(list(label2id.items())[:5])\n","    # loading testing data file\n","    with open(test_data_path,'r') as test_file:\n","        test_data=[json.loads(line) for line in test_file] # reading json data from data_path and parse it into a test_data list\n","\n","    num_classes=150\n","    # loading pretrained tokenizer\n","    tokenizer=RobertaTokenizer.from_pretrained(model_path)\n","    test_utt=[item['utt'] for item in test_data]\n","    test_data_encodings=tokenizer(test_utt, padding=True, truncation=True, return_tensors=\"pt\") # getting the encodings of testing data\n","\n","    # Convert the encodings into tensors\n","    input_ids = test_data_encodings['input_ids']\n","    attention_mask = test_data_encodings['attention_mask']\n","    # token_type_ids = test_set_encodings['token_type_ids'] # may be useful if our pretrained model is of type then roberta like BERT\n","\n","    # Create a TensorDataset\n","    test_dataset = TensorDataset(input_ids, attention_mask,)\n","\n","    # Define batch size\n","    batch_size = 32\n","\n","    # Create a DataLoader\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n","\n","    # loading the pretrained model\n","    model = RobertaForSequenceClassification.from_pretrained(model_path, num_labels=num_classes, ignore_mismatched_sizes=True)\n","    model.to(device)\n","\n","        # Initialize an empty list to store predictions\n","    predictions = []\n","\n","    # Set the model in evaluation mode\n","    model.eval()\n","\n","    # Iterate through the batches in the DataLoader\n","    for batch in test_dataloader:\n","        # Unpack the batch\n","        input_ids, attention_mask = batch\n","\n","        # Move tensors to the device (e.g., GPU if available)\n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","\n","\n","        # Forward pass to get logits\n","        with torch.no_grad():\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","\n","        # Extract the logits tensor from the outputs\n","        logits = outputs.logits\n","\n","        # Apply softmax to get class probabilities\n","        probabilities = torch.softmax(logits, dim=1)\n","\n","        # Get the predicted class (index with the highest probability)\n","        predicted_class = torch.argmax(probabilities, dim=1)\n","\n","        # Append the predicted class to the list of predictions\n","        predictions.extend(predicted_class.tolist())\n","\n","    predictions=torch.tensor(predictions) # predicted id for all the utterance of the testing data\n","\n","    predicted_labels=[id2label[int(id)] for id in list(predictions)] # converting those id into labels using id2label mapping made above\n","\n","    # converting these label with their id into pandas Dataframe\n","    my_id=[]\n","    my_intent=[]\n","    my_dict1={}\n","\n","    for i, entry in enumerate(test_data):\n","      my_id.append({'indoml_id':i+1,'intent':predicted_labels[i]})\n","      my_intent.append(predicted_labels[i])\n","      my_dict1['id']=my_id\n","      my_dict1['intent']=my_intent\n","\n","\n","    my_dict1_pd=pd.DataFrame.from_dict(my_dict1)\n","    print(my_dict1_pd)\n","\n","    # Converting the predictions into the desired format taken from the 1st column of my_dict1_pd dataframe\n","    # This output.predict file will got saved in the same directory where this jupyter file is present, you can also change the path of this where you want to save it accordingly.\n","    with open('output.predict', 'w') as out_file:\n","      for entry in my_dict1_pd['id']:\n","          out_file.write(str(entry))\n","          out_file.write('\\n')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ib2sgAGyvAP_","outputId":"4c74de42-7ac9-4cd7-c88a-ff6e6cb58aee"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                                     id  \\\n","0               {'indoml_id': 1, 'intent': 'what song'}   \n","1           {'indoml_id': 2, 'intent': 'change volume'}   \n","2                    {'indoml_id': 3, 'intent': 'time'}   \n","3              {'indoml_id': 4, 'intent': 'smart home'}   \n","4                {'indoml_id': 5, 'intent': 'carry on'}   \n","...                                                 ...   \n","5995            {'indoml_id': 5996, 'intent': 'cancel'}   \n","5996          {'indoml_id': 5997, 'intent': 'timezone'}   \n","5997         {'indoml_id': 5998, 'intent': 'roll dice'}   \n","5998          {'indoml_id': 5999, 'intent': 'carry on'}   \n","5999  {'indoml_id': 6000, 'intent': 'restaurant rese...   \n","\n","                      intent  \n","0                  what song  \n","1              change volume  \n","2                       time  \n","3                 smart home  \n","4                   carry on  \n","...                      ...  \n","5995                  cancel  \n","5996                timezone  \n","5997               roll dice  \n","5998                carry on  \n","5999  restaurant reservation  \n","\n","[6000 rows x 2 columns]\n"]}],"source":["# model_path=\"C:/Users/panka/Downloads/epoch_16-20231021T144106Z-001/epoch_16/\"\n","# data_path=\"C:/Users/panka/Desktop/IndoML/input_data_latest/indoml_phase2_data/\"\n","model_path=\"/content/drive/MyDrive/massive_accuracy_files_in_descending_order/intent_classification_It_bombay/trained_model_11_0.25_data_split_lr_4e_5_checkpoints/epoch_16\"\n","data_path=\"/content/drive/MyDrive/massive_accuracy_files_in_descending_order/intent_classification_It_bombay (1)/indoml_iit_bombay/surprise_data/\" # Directory or folder containing paths of all the files related to surprise data and massive testing data.\n","out_file=test(model_path, data_path)\n","# Convert the list of predictions to a tensor\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"-hy_wAQm0hd3"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}